{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 1: Data Collection, Preparation, and Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## packages needed for all functions\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pymongo\n",
    "import json\n",
    "import requests\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "#\n",
    "#\n",
    "# Section 1: Data Collection - Yelp JSON Data to MongoDB\n",
    "#\n",
    "#\n",
    "\n",
    "# Function: Reads data from a JSON file and stores it in MongoDB\n",
    "def yelp_json_to_mongoDB(path, file_name):\n",
    "    documents = []\n",
    "    \n",
    "    ## connect to mongodb\n",
    "    py_client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "    py_db = py_client[\"yelp\"]\n",
    "    py_col = py_db[file_name]\n",
    "\n",
    "    ## drop collection to start fresh\n",
    "    py_col.drop()\n",
    "\n",
    "    with open(path+file_name+'.json', 'r') as file:\n",
    "        ## read each json line from json file as a dict. Save all dicts to a list.\n",
    "        for line in file:\n",
    "            doc = json.loads(line)\n",
    "            ## insert one document into the mongodb collection\n",
    "            py_col.insert_one(doc)\n",
    "            #documents.append(doc)\n",
    "    \n",
    "    ## count the no. of documents in the collection\n",
    "    #print(\"Collection: \"+file_name+\" | Count: \" + str(py_col.count_documents({})))\n",
    "    \n",
    "#\n",
    "#\n",
    "# Section 2: Data Collection - Zomato API Data to MongoDB\n",
    "#\n",
    "#\n",
    "\n",
    "# Function: Reads data from API and stores in MongoDB\n",
    "def zomato_api_to_mongoDB():\n",
    "    \n",
    "    ## connect to mongodb\n",
    "    py_client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "    py_db = py_client[\"zomato\"]\n",
    "    py_col = py_db[\"restaurant\"]\n",
    "\n",
    "    ## drop collection to start fresh\n",
    "    py_col.drop()\n",
    "    \n",
    "    ## list of coordinates of top 12 cities with the most businesses in yelp. Only restaurants\n",
    "    ## from cities will be pulled from the Zomato API.\n",
    "    lat = ['36.114647',\n",
    "            '43.65107',\n",
    "            '33.448376',\n",
    "            '35.227085',\n",
    "            '33.501324',\n",
    "            '51.049999',\n",
    "            '40.440624',\n",
    "            '45.508888',\n",
    "            '33.424564',\n",
    "            '33.427204',\n",
    "            '33.307575',\n",
    "            '41.505493'\n",
    "            ]\n",
    "    long = ['-115.172813',\n",
    "            '-79.347015',\n",
    "            '-112.074036',\n",
    "            '-80.843124',\n",
    "            '-111.925278',\n",
    "            '-114.066666',\n",
    "            '-79.995888',\n",
    "            '-73.561668',\n",
    "            '-111.833267',\n",
    "            '-111.939896',\n",
    "            '-111.84494',\n",
    "            '-81.68129'\n",
    "            ]\n",
    "    headers = {\n",
    "        'Accept': 'application/json',\n",
    "        'user-key': 'dde4241f1d6e955145ea0dfe0c673e49',\n",
    "    }\n",
    "    \n",
    "    ## iterate through each city's coordinates\n",
    "    for i in range(len(lat)):\n",
    "        #print('City: {} | Lat: {} | Long: {}'.format(i+1, lat[i], long[i]))\n",
    "        cnt = 0\n",
    "        \n",
    "        ## 101, since only a maximum of 100 entries is pulled in total for each city, \n",
    "        ## and a maximum of 20 entries for each API request.\n",
    "        while cnt < 101:\n",
    "            req = (requests.get('https://developers.zomato.com/api/v2.1/search?start={}&count=20&lat={}&lon={}' \\\n",
    "                                .format(cnt, lat[i], long[i]), headers=headers)).json()\n",
    "            \n",
    "            for rest in req[\"restaurants\"]:\n",
    "                doc = rest[\"restaurant\"]\n",
    "                doc.pop(\"R\", None)\n",
    "                doc.pop(\"all_reviews\", None)\n",
    "                doc.pop(\"events_url\", None)\n",
    "                doc.pop(\"featured_image\", None)\n",
    "                doc.pop(\"menu_url\", None)\n",
    "                doc.pop(\"photos\", None)\n",
    "                doc.pop(\"photos_url\", None)\n",
    "                doc.pop(\"thumb\", None)\n",
    "                doc.pop(\"apikey\", None)\n",
    "                doc.pop(\"url\", None)\n",
    "                py_col.insert_one(doc)\n",
    "            cnt = cnt + 20\n",
    "\n",
    "#\n",
    "#\n",
    "# Section 3: Data Preparation - Create Tables in Postgres\n",
    "#\n",
    "#\n",
    "\n",
    "# Function: Creates Postgres tables\n",
    "def create_tables_postgres():\n",
    "    ## open db connection\n",
    "    pg_conn = psycopg2.connect(database='postgres',\n",
    "                               host='localhost',\n",
    "                               port = '5432',\n",
    "                               user='postgres',\n",
    "                               password='postgres')\n",
    "    pg_conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT) ## set auto commit on\n",
    "    pg_cursor = pg_conn.cursor() ## open db cursor\n",
    "\n",
    "    ## recreate database, if already exists\n",
    "    pg_cursor.execute('DROP DATABASE IF EXISTS yelp;')\n",
    "    pg_cursor.execute('CREATE DATABASE yelp;')\n",
    "\n",
    "    ## creating UNLOGGED tables to increase the write performance\n",
    "    ## e.g.: For 192,609 records, it took 45 minutes without 'UNCLOGGED', and 3 minutes with 'UNCLOGGED'.\n",
    "    q_business = '''\n",
    "    CREATE UNLOGGED TABLE IF NOT EXISTS business (\n",
    "    business_id CHAR (22) PRIMARY KEY,\n",
    "    name VARCHAR (100),\n",
    "    address VARCHAR (520),\n",
    "    city VARCHAR (60),\n",
    "    state CHAR (3),\n",
    "    postal_code VARCHAR (10),\n",
    "    latitude DOUBLE PRECISION,\n",
    "    longitude DOUBLE PRECISION,\n",
    "    stars FLOAT8,\n",
    "    review_count INTEGER,\n",
    "    is_open INTEGER,\n",
    "    attributes VARCHAR (2000),\n",
    "    categories VARCHAR (2000),\n",
    "    hours VARCHAR (520)\n",
    "    );\n",
    "    '''\n",
    "\n",
    "    q_users = '''\n",
    "    CREATE UNLOGGED TABLE IF NOT EXISTS users (\n",
    "    users_id CHAR (22) PRIMARY KEY,\n",
    "    name VARCHAR (50),\n",
    "    review_count INTEGER,\n",
    "    yelping_since DATE,\n",
    "    useful INTEGER,\n",
    "    funny INTEGER,\n",
    "    cool INTEGER,\n",
    "    elite VARCHAR (100),\n",
    "    friends VARCHAR (1000000),\n",
    "    fans INTEGER,\n",
    "    average_stars FLOAT8,\n",
    "    compliment_hot INTEGER,\n",
    "    compliment_more INTEGER,\n",
    "    compliment_profile INTEGER,\n",
    "    compliment_cute INTEGER,\n",
    "    compliment_list INTEGER,\n",
    "    compliment_note INTEGER,\n",
    "    compliment_plain INTEGER,\n",
    "    compliment_cool INTEGER,\n",
    "    compliment_funny INTEGER,\n",
    "    compliment_writer INTEGER,\n",
    "    compliment_photos INTEGER\n",
    "    );\n",
    "    '''\n",
    "    \n",
    "    q_tip = '''\n",
    "    CREATE UNLOGGED TABLE IF NOT EXISTS tip (\n",
    "    business_id CHAR (22) REFERENCES business (business_id),\n",
    "    users_id CHAR (22) REFERENCES users (users_id),\n",
    "    text VARCHAR (5000),\n",
    "    date CHAR (22),\n",
    "    compliment_count INTEGER\n",
    "    );\n",
    "    '''\n",
    "\n",
    "    q_checkin = '''\n",
    "    CREATE UNLOGGED TABLE IF NOT EXISTS checkin (\n",
    "    business_id CHAR (22) REFERENCES business (business_id),\n",
    "    date VARCHAR (5000000)\n",
    "    );\n",
    "    '''\n",
    "\n",
    "    q_review = '''\n",
    "    CREATE UNLOGGED TABLE IF NOT EXISTS review (\n",
    "    review_id CHAR (22) PRIMARY KEY,\n",
    "    users_id CHAR (22) REFERENCES users (users_id),\n",
    "    business_id CHAR (22) REFERENCES business (business_id),\n",
    "    stars FLOAT8,\n",
    "    useful INTEGER,\n",
    "    funny INTEGER,\n",
    "    cool INTEGER,\n",
    "    text VARCHAR (20000),\n",
    "    date CHAR (22)\n",
    "    );\n",
    "    '''\n",
    "    \n",
    "    q_restaurant = '''\n",
    "    CREATE UNLOGGED TABLE IF NOT EXISTS restaurant (\n",
    "    restaurant_id VARCHAR (15) PRIMARY KEY,\n",
    "    name VARCHAR(100),\n",
    "    city VARCHAR (50),\n",
    "    latitude DOUBLE PRECISION,\n",
    "    longitude DOUBLE PRECISION,\n",
    "    zipcode VARCHAR (50),\n",
    "    cuisines VARCHAR (100),\n",
    "    average_cost_for_two INTEGER,\n",
    "    aggregate_rating FLOAT8,\n",
    "    rating_text VARCHAR (20),\n",
    "    votes INTEGER,\n",
    "    all_reviews_count INTEGER,\n",
    "    photo_count INTEGER,\n",
    "    has_online_delivery INTEGER\n",
    "    );\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        ## delete tables if already exist\n",
    "        pg_cursor.execute('DROP TABLE IF EXISTS business CASCADE;')\n",
    "        pg_cursor.execute('DROP TABLE IF EXISTS users CASCADE;')\n",
    "        pg_cursor.execute('DROP TABLE IF EXISTS tip CASCADE;')\n",
    "        pg_cursor.execute('DROP TABLE IF EXISTS checkin CASCADE;')\n",
    "        pg_cursor.execute('DROP TABLE IF EXISTS review CASCADE;')\n",
    "        pg_cursor.execute('DROP TABLE IF EXISTS restaurant CASCADE;')\n",
    "        \n",
    "        ## create tables in postgres\n",
    "        pg_cursor.execute(q_business)\n",
    "        pg_cursor.execute(q_users)\n",
    "        pg_cursor.execute(q_tip)\n",
    "        pg_cursor.execute(q_checkin)\n",
    "        pg_cursor.execute(q_review)\n",
    "        pg_cursor.execute(q_restaurant)\n",
    "    \n",
    "    except (Exception, psycopg2.Error) as dbError:\n",
    "        print (\"Error while connecting to PostgreSQL\", dbError)\n",
    "    finally:\n",
    "        if(pg_conn): pg_conn.close()\n",
    "\n",
    "#\n",
    "#\n",
    "# Section 4: Data Preparation - Read from MongoDB, Clean, Write to Postgres\n",
    "#\n",
    "#\n",
    "\n",
    "# Function: Escapes single and double quotes since attributes from json.dumps() are enclosed in double quotes. Double\n",
    "# quotes cause problems in SQL INSERT statements.\n",
    "def esc(s):\n",
    "    if s == 'null':\n",
    "        return '\\'\\''\n",
    "    # E tells postgres to use backslash before apostrophe to escape the apostrophe\n",
    "    return 'E\\''+s.replace('\\\\','\\\\\\\\').replace('\"', '\\\\\\\"').replace(\"'\", \"\\\\\\'\")+'\\'' if isinstance(s, str) else '\\'\\''\n",
    "\n",
    "# Function: Reads data from MongoDB and stores in Postgres\n",
    "def write_tables_postgres():\n",
    "    \n",
    "    ## Connect to MongoDB\n",
    "    m_client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "    m_col = \"\"\n",
    "    \n",
    "    ## Connect to Postgres\n",
    "    pg_conn = psycopg2.connect(database='postgres',\n",
    "                               host='localhost',\n",
    "                               port = '5432',\n",
    "                               user='postgres',\n",
    "                               password='postgres')\n",
    "    pg_conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    pg_cursor = pg_conn.cursor()\n",
    "    \n",
    "    for col in ['business', 'checkin', 'tip', 'user', 'review']:\n",
    "        m_col = m_client[\"yelp\"][col] ## connect to the yelp db MongoDB\n",
    "        \n",
    "        if col == 'business':\n",
    "            print(\"Info: Writing to business table...\")\n",
    "            for doc in m_col.find():\n",
    "                query = \"INSERT INTO business VALUES (\"+\"{},\"*13+\"{})\"\n",
    "                query = query.format(esc(doc['business_id']),\n",
    "                            esc(doc['name']),\n",
    "                            esc(doc['address']),\n",
    "                            esc(doc['city']),\n",
    "                            esc(doc['state']),\n",
    "                            esc(doc['postal_code']),\n",
    "                            doc['latitude'],\n",
    "                            doc['longitude'],\n",
    "                            doc['stars'],\n",
    "                            doc['review_count'],\n",
    "                            doc['is_open'],\n",
    "                            esc(json.dumps(doc['attributes'])),\n",
    "                            esc(doc['categories']),\n",
    "                            esc(json.dumps(doc['hours'])))\n",
    "                pg_cursor.execute(query)\n",
    "            print(\"Info: Writing to business table... Completed\")\n",
    "            \n",
    "        elif col == 'user':\n",
    "            print(\"Info: Writing to users table...\")\n",
    "            for doc in m_col.find():\n",
    "                query = \"INSERT INTO users VALUES (\"+\"{},\"*21+\"{})\"\n",
    "                query = query.format(esc(doc['user_id']),\n",
    "                            esc(doc['name']),\n",
    "                            doc['review_count'],\n",
    "                            'TO_TIMESTAMP(\\''+doc['yelping_since']+'\\',\\'YYYY-MM-DD HH24:MI:SS\\')',\n",
    "                            doc['useful'],\n",
    "                            doc['funny'],\n",
    "                            doc['cool'],\n",
    "                            esc(doc['elite']),\n",
    "                            esc(doc['friends']),\n",
    "                            doc['fans'],\n",
    "                            doc['average_stars'],\n",
    "                            doc['compliment_hot'],\n",
    "                            doc['compliment_more'],\n",
    "                            doc['compliment_profile'],\n",
    "                            doc['compliment_cute'],\n",
    "                            doc['compliment_list'],\n",
    "                            doc['compliment_note'],\n",
    "                            doc['compliment_plain'],\n",
    "                            doc['compliment_cool'],\n",
    "                            doc['compliment_funny'],\n",
    "                            doc['compliment_writer'],\n",
    "                            doc['compliment_photos'])\n",
    "                pg_cursor.execute(query)\n",
    "            print(\"Info: Writing to users table... Completed\")\n",
    "            \n",
    "        elif col == 'review':\n",
    "            print(\"Info: Writing to review table...\")\n",
    "            for doc in m_col.find():\n",
    "                query = \"INSERT INTO review VALUES (\"+\"{},\"*8+\"{})\"\n",
    "                query = query.format(esc(doc['review_id']),\n",
    "                            esc(doc['user_id']),\n",
    "                            esc(doc['business_id']),\n",
    "                            doc['stars'],\n",
    "                            doc['useful'],\n",
    "                            doc['funny'],\n",
    "                            doc['cool'],\n",
    "                            esc(doc['text']),\n",
    "                            'TO_TIMESTAMP(\\''+doc['date']+'\\',\\'YYYY-MM-DD HH24:MI:SS\\')')\n",
    "                pg_cursor.execute(query)\n",
    "            print(\"Info: Writing to review table... Completed\")\n",
    "            \n",
    "        elif col == 'tip':\n",
    "            print(\"Info: Writing to tip table...\")\n",
    "            for doc in m_col.find():\n",
    "                query = \"INSERT INTO tip VALUES (\"+\"{},\"*4+\"{})\"\n",
    "                query = query.format(esc(doc['business_id']),\n",
    "                            esc(doc['user_id']),\n",
    "                            esc(doc['text']),\n",
    "                            'TO_TIMESTAMP(\\''+doc['date']+'\\',\\'YYYY-MM-DD HH24:MI:SS\\')',\n",
    "                            doc['compliment_count'])\n",
    "                pg_cursor.execute(query)\n",
    "            print(\"Info: Writing to tip table... Completed\")\n",
    "            \n",
    "        elif col == 'checkin':\n",
    "            print(\"Info: Writing to checkin table...\")\n",
    "            for doc in m_col.find():\n",
    "                query = \"INSERT INTO checkin VALUES ({},{})\"\n",
    "                query = query.format(esc(doc['business_id']),\n",
    "                            esc(doc['date']))\n",
    "                pg_cursor.execute(query)\n",
    "            print(\"Info: Writing to checkin table... Completed\")\n",
    "    \n",
    "    for col in ['restaurant']:\n",
    "        m_col = m_client[\"zomato\"][col] ## connect to the zomato db in MongoDB\n",
    "        \n",
    "        if col == 'restaurant':               \n",
    "            print(\"Info: Writing to restaurant table...\")\n",
    "            for doc in m_col.find():\n",
    "                query = \"INSERT INTO restaurant VALUES (\"+\"{},\"*13+\"{})\"\n",
    "                query = query.format(esc(doc['id']),\n",
    "                            esc(doc['name']),\n",
    "                            esc(doc['location']['city']),\n",
    "                            doc['location']['latitude'],\n",
    "                            doc['location']['longitude'],\n",
    "                            esc(doc['location']['zipcode']),\n",
    "                            esc(doc['cuisines']),\n",
    "                            doc['average_cost_for_two'],\n",
    "                            doc['user_rating']['aggregate_rating'],\n",
    "                            esc(doc['user_rating']['rating_text']),\n",
    "                            doc['user_rating']['votes'],\n",
    "                            doc['all_reviews_count'],\n",
    "                            doc['photo_count'],\n",
    "                            doc['has_online_delivery'])\n",
    "                pg_cursor.execute(query)\n",
    "            print(\"Info: Writing to restaurant table... Completed\")\n",
    "\n",
    "\n",
    "def run_extraction_storage():\n",
    "    path = os.getcwd()+'/yelp_dataset/'\n",
    "    file_names = ['business', 'checkin', 'tip', 'tip', 'user', 'review']\n",
    "\n",
    "    print(\"yelp_json_to_mongoDB() - Start -> \" + str(datetime.now().time()))\n",
    "    for file in file_names:\n",
    "        yelp_json_to_mongoDB(path, file)\n",
    "    print(\"yelp_json_to_mongoDB() - Finish -> \" + str(datetime.now().time()))\n",
    "    \n",
    "    print(\"zomato_api_to_mongoDB() - Start -> \" + str(datetime.now().time()))\n",
    "    zomato_api_to_mongoDB()\n",
    "    print(\"zomato_api_to_mongoDB() - Finish -> \" + str(datetime.now().time()))\n",
    "    \n",
    "    print(\"create_tables_postgres() - Start -> \" + str(datetime.now().time()))\n",
    "    create_tables_postgres()\n",
    "    print(\"create_tables_postgres() - Finish -> \" + str(datetime.now().time()))\n",
    "    \n",
    "    print(\"write_tables_postgres() - Start -> \" + str(datetime.now().time()))\n",
    "    write_tables_postgres()\n",
    "    print(\"write_tables_postgres() - Finish -> \" + str(datetime.now().time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 2: Data Analysis - Analysing Ratings of Yelp and Zomato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "mergedf1 = pd.DataFrame()\n",
    "\n",
    "def dataread():\n",
    "    ## Connect to Postgres\n",
    "    pg_conn = psycopg2.connect(database='postgres',\n",
    "                               host='localhost',\n",
    "                               port = '5432',\n",
    "                               user='postgres',\n",
    "                               password='Shreyshah9')\n",
    "    pg_conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    pg_cursor = pg_conn.cursor()\n",
    "    \n",
    "    #checkin, restaurant\n",
    "    query = \"select r.restaurant_id, b.business_id, r.name, r.city, r.aggregate_rating, b.stars, r.votes, b.review_count from restaurant r, business b where r.name = b.name and ROUND(r.latitude::numeric, 3) = ROUND(b.latitude::numeric, 3) and ROUND(r.longitude::numeric, 3) = ROUND(b.longitude::numeric, 3)\"\n",
    "    #print(query)\n",
    "    mergedf = pd.read_sql_query(query, pg_conn)\n",
    "    #display(mergedf)\n",
    "    mergedf1['zom_id'] = mergedf['restaurant_id']\n",
    "    mergedf1['yelp_id'] = mergedf['business_id']\n",
    "    mergedf1['name'] = mergedf['name']\n",
    "    mergedf1['city'] = mergedf['city']\n",
    "    mergedf1['zom_ratings'] = mergedf['aggregate_rating']\n",
    "    mergedf1['yelp_ratings'] = mergedf['stars']\n",
    "    mergedf1['zom_votes'] = mergedf['votes']\n",
    "    mergedf1['yelp_votes'] = mergedf['review_count']\n",
    "    pg_conn.close()\n",
    "    \n",
    "## Function: 1st set of Visualizations\n",
    "def run_visualization_1():\n",
    "    dataread()\n",
    "    \n",
    "    # Plot 1\n",
    "    plt.plot(mergedf1.zom_ratings, color='coral')\n",
    "    plt.plot(mergedf1.yelp_ratings, color='grey')\n",
    "    plt.xlabel('Restaurants')\n",
    "    plt.ylabel('Ratings out of 5')\n",
    "    plt.title('Yelp vs Zomato ratings comparison')\n",
    "    rp = mpatches.Patch(color='coral', label='Zomato Ratings')\n",
    "    gp = mpatches.Patch(color='grey', label='Yelp Ratings')\n",
    "    plt.legend(handles=[rp, gp])\n",
    "    plt.savefig('plot_before_adj.png', transparent=True, dpi=2000)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 2\n",
    "    plt.plot(mergedf1.zom_votes, color='coral')\n",
    "    plt.plot(mergedf1.yelp_votes, color='grey')\n",
    "    plt.xlabel('Restaurant ids')\n",
    "    plt.ylabel('Total number of votes')\n",
    "    plt.title('Yelp vs Zomato votes comparison')\n",
    "    rp = mpatches.Patch(color='coral', label='Zomato votes')\n",
    "    gp = mpatches.Patch(color='grey', label='Yelp votes')\n",
    "    plt.legend(handles=[rp, gp])\n",
    "    plt.savefig('plot_votes.png', transparent=True, dpi=2000)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    #Plot 3: Scatterplot (Here it is observed yelp has only absolute values with intervals of 0.5 and zomato has interval of 0.1)\n",
    "    plt.scatter( mergedf1.index, mergedf1.zom_ratings, color='coral')\n",
    "    plt.scatter( mergedf1.index, mergedf1.yelp_ratings, color='grey')\n",
    "    plt.savefig('scatter_before_adj.png', transparent=True, dpi=2000)\n",
    "    plt.show()\n",
    "    \n",
    "    #Creating new dataframe to perform further operations on duplicate database to prevent losing actual data\n",
    "    C = pd.DataFrame()\n",
    "    \n",
    "    C['zom_ratings'] = mergedf1['zom_ratings']\n",
    "    C['yelp_ratings'] = mergedf1['yelp_ratings']\n",
    "    C['zom_votes'] = mergedf1['zom_votes']\n",
    "    C['yelp_votes'] = mergedf1['yelp_votes']\n",
    "    \n",
    "    #Converting zomato ratings to absolute ratings as well like yelp for unbiased visualization\n",
    "    C.loc[C['zom_ratings'] > 4.75, 'zom_ratings'] = 5\n",
    "    C.loc[(C['zom_ratings'] > 4.25) & (C['zom_ratings'] <= 4.75), 'zom_ratings'] = 4.50\n",
    "    C.loc[(C['zom_ratings'] > 3.75) & (C['zom_ratings'] <= 4.25), 'zom_ratings'] = 4.00\n",
    "    C.loc[(C['zom_ratings'] > 3.25) & (C['zom_ratings'] <= 3.75), 'zom_ratings'] = 3.50\n",
    "    C.loc[(C['zom_ratings'] > 2.75) & (C['zom_ratings'] <= 3.25), 'zom_ratings'] = 3.00\n",
    "    C.loc[(C['zom_ratings'] > 2.25) & (C['zom_ratings'] <= 2.75), 'zom_ratings'] = 2.50\n",
    "    C.loc[(C['zom_ratings'] > 1.75) & (C['zom_ratings'] <= 2.25), 'zom_ratings'] = 2.00\n",
    "    \n",
    "    yelp_mean = (C.yelp_ratings).mean()\n",
    "    zom_mean = (C.zom_ratings).mean()\n",
    "    \n",
    "    #Plot 4: Scatterplot after converting zomato ratings to absolute values\n",
    "    list_length = len(C.index)\n",
    "    plt.scatter( C.index, C.zom_ratings, color='coral')\n",
    "    plt.plot(C.index, [zom_mean] * list_length  , label='Mean', linestyle='--', color = \"coral\")\n",
    "    plt.scatter( C.index, C.yelp_ratings, marker='x', color='grey')\n",
    "    plt.plot(C.index, [yelp_mean] * list_length  , label='Mean', linestyle='--', color = \"grey\")\n",
    "    plt.title('Yelp vs Zomato ratings comparison')\n",
    "    rp = mpatches.Patch(color='coral', label='Zomato Ratings')\n",
    "    gp = mpatches.Patch(color='grey', label='Yelp Ratings')\n",
    "    plt.legend(handles=[rp, gp])\n",
    "    plt.xlabel('Restaurant ids')\n",
    "    plt.ylabel('Ratings out of 5')\n",
    "    plt.savefig('scatter_after_adj.png', dpi=2000)\n",
    "    \n",
    "    #Plot 5After conversion to zomato absolute values\n",
    "    plt.plot(C.zom_ratings, color='coral')\n",
    "    plt.plot(C.yelp_ratings, color='grey')\n",
    "    plt.xlabel('Restaurants')\n",
    "    plt.ylabel('Ratings out of 5')\n",
    "    plt.title('Yelp vs Zomato ratings comparison')\n",
    "    rp = mpatches.Patch(color='coral', label='Zomato Ratings')\n",
    "    gp = mpatches.Patch(color='grey', label='Yelp Ratings')\n",
    "    plt.legend(handles=[rp, gp])\n",
    "    plt.savefig('line_after_adj.png', transparent=True, dpi=2000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 3: Data Analysis - Analysing Rating Differences and how Cuisines affect them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import folium\n",
    "\n",
    "## Function: Retreives 391 restaurants from both the Yelp and Zomato datasets\n",
    "def get_data(s_query='XXX'):\n",
    "    ## Connect to Postgres\n",
    "    pg_conn = psycopg2.connect(database='postgres',\n",
    "                               host='localhost',\n",
    "                               port = '5432',\n",
    "                               user='postgres',\n",
    "                               password='postgres')\n",
    "    pg_conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    pg_cursor = pg_conn.cursor()\n",
    "\n",
    "    query = '''\n",
    "    select b.name, r.restaurant_id as zom_id, b.business_id as yelp_id, \n",
    "    r.aggregate_rating as zom_rating, b.stars as yelp_rating,\n",
    "    b.latitude as lat, b.longitude as long,\n",
    "    r.votes as zom_rtg_count, b.review_count as yelp_rtg_count\n",
    "    from restaurant r, business b\n",
    "    where r.name = b.name\n",
    "    and ROUND(r.latitude::numeric, 3) = ROUND(b.latitude::numeric, 3)\n",
    "    and ROUND(r.longitude::numeric, 3) = ROUND(b.longitude::numeric, 3)\n",
    "    '''\n",
    "    \n",
    "    if s_query != 'XXX':\n",
    "        query = s_query\n",
    "\n",
    "    df = pd.read_sql_query(query, pg_conn)\n",
    "\n",
    "    pg_conn.close()\n",
    "    return df\n",
    "\n",
    "## Function: Bins the rating differences between the sites\n",
    "def bin_diff(diff):\n",
    "    diff = round(diff, 2)\n",
    "    if diff == 0:\n",
    "        return 'None'\n",
    "    elif diff >= 0.1 and diff <= 0.5:\n",
    "        return 'Low'\n",
    "    elif diff > 0.5 and diff <= 1.0:\n",
    "        return 'Medium'\n",
    "    elif diff > 1.0 and diff <= 1.5:\n",
    "        return 'High'\n",
    "\n",
    "## Function: Transform the data and create necessary additional columns\n",
    "def transform_data(df):\n",
    "    df['zom_per'] = df.apply(lambda x: round((x['zom_rtg_count']*100)/(x['zom_rtg_count']+x['yelp_rtg_count']),2), axis=1)\n",
    "    df['yelp_per'] = df.apply(lambda x: round((x['yelp_rtg_count']*100)/(x['zom_rtg_count']+x['yelp_rtg_count']),2), axis=1)\n",
    "    df['diff_signed'] = df['zom_rating'] - df['yelp_rating']\n",
    "    df['diff'] = df.apply(lambda x: (x['diff_signed'] * -1) if x['diff_signed'] < 0 else x['diff_signed'], axis=1)\n",
    "    df['bin'] = df.apply(lambda x: bin_diff(x['diff']), axis=1)\n",
    "    return df\n",
    "\n",
    "## Function: Plot shows the distribution of restaurants along the polarized rating bins\n",
    "def diff_bin_plot_1(df):\n",
    "    x = df['bin'].value_counts()\n",
    "    x = x.reindex(index = ['None','Low','Medium','High'])\n",
    "    x = x.rename(index={'Low':'Low\\n(0.1 to 0.5)', 'Medium':'Medium\\n(0.6 to 1.0)', 'High':'High\\n(1.1 to 1.5)'})\n",
    "    plt.figure(figsize=(8,7))\n",
    "    colours = ['grey' if (i > min(x.values)) else 'red' for i in x.values ]\n",
    "    sb.set(font_scale = 1.2)\n",
    "    ax = sb.barplot(x.index, x.values, palette=colours, alpha=0.9)\n",
    "    plt.title(\"Polarization of Restaurant Ratings\", fontsize=24, fontweight='bold')\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.setp(labels, rotation=0, fontsize=14)\n",
    "    plt.ylabel('# of Restaurants', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Differences in Ratings Across Zomato & Yelp', fontsize=14, fontweight='bold')\n",
    "\n",
    "    #adding the text labels\n",
    "    rects = ax.patches\n",
    "    labels = x.values\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "    plt.show()\n",
    "\n",
    "## Function: Gives marker background color for the map point of the restaurant based on its rating bin\n",
    "def get_marker_colour(rating_bin):\n",
    "    if rating_bin == 'None':\n",
    "        return 'white'\n",
    "    elif rating_bin == 'Low':\n",
    "        return 'lightgray'\n",
    "    elif rating_bin == 'Medium':\n",
    "        return 'gray'\n",
    "    elif rating_bin == 'High':\n",
    "        return 'red'\n",
    "\n",
    "## Function: Displays the map of the restaurants having a 'High' rating difference\n",
    "def folium_plot_2(df):\n",
    "    df = df[df['bin']=='High']\n",
    "    m = folium.Map(location=[41.878113, -87.629799], tiles='Stamen Terrain', zoom_start=5,control_scale=True)\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        folium.Marker([df.iloc[i]['lat'], df.iloc[i]['long']], \\\n",
    "                popup=\"<strong>\"+df.iloc[i]['name']+\" (\"+str(round(df.iloc[i]['diff'],2))+\")\"\"</strong>\", \\\n",
    "                icon=folium.Icon(color=get_marker_colour(df.iloc[i]['bin']), icon_color='black', icon='glyphicon glyphicon-cutlery', angle=0)) \\\n",
    "                .add_to(m)        \n",
    "    display(m)\n",
    "\n",
    "def draw_cusine(df, site, heading):\n",
    "    x=df.category.value_counts()\n",
    "    x=x.sort_values(ascending=False)\n",
    "    x=x.iloc[0:6]\n",
    "    \n",
    "    plt.figure(figsize=(8,7))\n",
    "    colours = ['grey' if (i < max(x.values)) else 'red' for i in x.values ]\n",
    "    sb.set(font_scale = 1.2)\n",
    "    ax = sb.barplot(x.index, x.values, palette=colours, alpha=0.9)\n",
    "    ax.tick_params(labelsize=12)\n",
    "    plt.title(heading, fontsize=20, fontweight='bold')\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.setp(labels, rotation=45, fontsize=12)\n",
    "    plt.ylabel('# of Restaurants', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Cuisines', fontsize=14, fontweight='bold')\n",
    "\n",
    "    #adding the text labels\n",
    "    rects = ax.patches\n",
    "    labels = x.values\n",
    "    for rect, label in zip(rects, labels):\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2, height, label, ha='center', va='bottom')\n",
    "    plt.show()\n",
    "\n",
    "## Function: Plots of top 6 cuisines in each rating difference category \n",
    "def cuisine_plot_3(df):\n",
    "    for level in ['Low', 'Medium', 'High']:\n",
    "        zom_id_high = df[df['bin']==level]['zom_id'].tolist()\n",
    "        zomato = get_data('select * from restaurant')\n",
    "        zomato = zomato[zomato['restaurant_id'].isin(zom_id_high)]\n",
    "        zom_cat = ', '.join(zomato['cuisines']).split(', ') # cuisine list\n",
    "        zom_df = pd.DataFrame(zom_cat, columns=['category'])\n",
    "        draw_cusine(zom_df, 'zomato', 'Zomato Cuisines of \\''+level+'\\' Polarized Restaurants')  \n",
    "        \n",
    "        yelp_id_high = df[df['bin']==level]['yelp_id'].tolist()\n",
    "        yelp = get_data('select * from business')\n",
    "        yelp = yelp[yelp['business_id'].isin(yelp_id_high)]\n",
    "        yelp_cat = ', '.join(yelp['categories']).split(', ')\n",
    "        # Ignore 'Restaurants' and 'Food' since they are common in most restaurants\n",
    "        yelp_cat = [ele for ele in yelp_cat if ele not in {'Restaurants','Food'}] \n",
    "        yelp_df = pd.DataFrame(yelp_cat, columns=['category'])\n",
    "        draw_cusine(yelp_df, 'yelp', 'Yelp Categories of \\''+level+'\\' Polarized Restaurants')\n",
    "\n",
    "## Function: 2nd set of Visualizations\n",
    "def run_visualization_2():\n",
    "    df = get_data() # df is the dataframe with common 391 retaurants between zomato and yelp\n",
    "    df = transform_data(df)\n",
    "    diff_bin_plot_1(df)\n",
    "    folium_plot_2(df)\n",
    "    cuisine_plot_3(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 4: Data Analysis - Analysing Yelp's Review Dataset using Sentiment Analysis using Wordclouds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#misc\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "#viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import matplotlib.gridspec as gridspec \n",
    "import matplotlib.gridspec as gridspec \n",
    "\n",
    "# graph viz\n",
    "import plotly.offline as pyo\n",
    "from plotly.graph_objs import *\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from collections import Counter \n",
    "from wordcloud import WordCloud, STOPWORDS # wordcloud in python\n",
    "\n",
    "import re \n",
    "import string\n",
    "import nltk # preprocessing text\n",
    "from textblob import TextBlob\n",
    "\n",
    "def sentiment(x):\n",
    "    sentiment = TextBlob(x)\n",
    "    return sentiment.sentiment.polarity\n",
    "\n",
    "# function for pre-processing the text of reviews: this function remove punctuation, stopwords and returns the list of words\n",
    "def preprocess(x):\n",
    "    x = re.sub('[^a-z\\s]', '', x.lower())                  \n",
    "    x = [w for w in x.split() if w not in set(stopwords)]  \n",
    "    return ' '.join(x)\n",
    "\n",
    "## Function: 3rd set of Visualizations\n",
    "def run_visualization_3():\n",
    "    review=pd.read_csv(\"review match.csv\")\n",
    "    nltk.download(\"stopwords\")\n",
    "\n",
    "    #removing stop words\n",
    "    i = nltk.corpus.stopwords.words('english')\n",
    "    # punctuations to remove\n",
    "    j = list(string.punctuation)\n",
    "    # finally let's combine all of these\n",
    "    stopwords = set(i).union(j).union(('thiswas','wasbad','thisis','wasgood','isbad','isgood','theres','there'))4\n",
    "\n",
    "    review['text_processed'] = review['text'].apply(preprocess)\n",
    "\n",
    "    #Top reviewed words\n",
    "    wordcloud = WordCloud(width=1600, height=800, random_state=1, max_words=500, background_color='white',)\n",
    "    wordcloud.generate(str(set(review['text_processed'])))\n",
    "    # declare our figure \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title(\"Top Reviewed words\", fontsize=40,color='Red')\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad=10)\n",
    "    plt.show()\n",
    "\n",
    "    def sentiment(x):\n",
    "        sentiment = TextBlob(x)\n",
    "        return sentiment.sentiment.polarity\n",
    "\n",
    "    review['text_sentiment'] = review['text_processed'].apply(sentiment)\n",
    "\n",
    "    review['sentiment'][review['text_sentiment'] > 0] = 'positive'\n",
    "    review['sentiment'][review['text_sentiment'] < 0] = 'negative'\n",
    "    review['sentiment'][review['text_sentiment'] == 0] = 'neutral'\n",
    "\n",
    "    #Review Sentiments count\n",
    "    plt.figure(figsize=(6,6))\n",
    "    ax = sns.countplot(review['sentiment'])\n",
    "    plt.title('Review Sentiments');\n",
    "\n",
    "    review_posr = pd.DataFrame(review['text_processed'][ review['sentiment'] == 'positive'])\n",
    "    review_negr = pd.DataFrame(review['text_processed'][ review['sentiment'] == 'negative'])\n",
    "    review_neutr = pd.DataFrame(review['text_processed'][ review['sentiment'] == 'neutral'])\n",
    "\n",
    "    #Positive Sentiment cloud\n",
    "    wordcloud = WordCloud(width=1600, height=800, random_state=1, max_words=500, background_color='white',)\n",
    "    wordcloud.generate(str(set(review_posr['text_processed'])))\n",
    "    # declare our figure \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title(\"Positive Sentiment\", fontsize=40,color='Red')\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad=10)\n",
    "    plt.show()\n",
    "\n",
    "    #Negative sentiment cloud\n",
    "    wordcloud = WordCloud(width=1600, height=800, random_state=1, max_words=500, background_color='white',)\n",
    "    wordcloud.generate(str(set(review_negr['text_processed'])))\n",
    "    # declare our figure \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title(\"Negative Sentiment\", fontsize=40,color='Red')\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad=10)\n",
    "    plt.show()\n",
    "\n",
    "    wordcloud = WordCloud(width=1600, height=800, random_state=1, max_words=500, background_color='white',)\n",
    "    wordcloud.generate(str(set(review_neutr['text_processed'])))\n",
    "    # declare our figure \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title(\"Neutral Sentiment\", fontsize=40,color='Red')\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad=10)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function (Start Point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Main Function:\n",
    "#\n",
    "#\n",
    "def main():\n",
    "    run_extraction_storage()\n",
    "    run_visualization_1()\n",
    "    run_visualization_2()\n",
    "    run_visualization_3()\n",
    "    pass\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
